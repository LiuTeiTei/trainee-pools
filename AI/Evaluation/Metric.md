# 模型本身能力

## Entropy

> *Entropy* measures how much information, on average, a token carries. 
>
> The higher the entropy, the more information each token carries, and the more bits are needed to represent a token.

通俗理解就是：衡量“事情的混乱程度”或“不确定性”。

**核心思想：** 熵就是“惊喜度”。一件事的结果越不确定、越出乎意料，它的熵就越高。

**生活例子：抛硬币**

- **情况A：一个正常的硬币**
  - 正面朝上：50% 概率
  - 反面朝上：50% 概率
  - 结果非常不确定，每次抛之前你都会很好奇结果是什么。这种情况的**熵很高**。
- **情况B：一个动了手脚的硬币**
  - 正面朝上：99% 概率
  - 反面朝上：1% 概率
  - 结果几乎可以肯定是正面，非常确定，没什么惊喜。这种情况的**熵很低**。

**在语言模型中的意义：**
熵用来衡量一段文本的“不可预测性”。比如：

- **“地球是___的”**：后面接“圆”、“平”等词的概率比较集中，不确定性相对较低，所以熵较低。
- **“今天天气真___”**：后面可以接“好”、“坏”、“热”、“冷”、“奇怪”等无数种可能，非常不确定，所以熵较高。

**小结：熵 (Entropy) 就是衡量一个事件本身有多大的不确定性。不确定性越大，熵越大。**



## Cross Entropy

> A language model’s cross entropy on a dataset measures how difficult it is for the language model to predict what comes next in this dataset.

通俗理解就是：衡量“我的预测和现实差距有多大”

**核心思想：** 我用我的理解（一个估计的概率分布）去预测真实的事件，我的预测到底有多不准？这个“不准的程度”就是交叉熵。

**生活例子：预测天气**

- **真实情况（上帝视角）**：明天 100% 会下雨。
- **你的预测A（很准）**：你认为明天 90% 下雨，10% 不下雨。
  - 虽然不完全正确，但很接近现实。你的“惊讶程度”（交叉熵）比较低。
- **你的预测B（很不准）**：你认为明天 10% 下雨，90% 出太阳。
  - 这和现实差距极大！当第二天真的下雨时，你会感到“非常惊讶”。你的“惊讶程度”（交叉熵）就非常高。

**在语言模型中的意义：**
交叉熵是语言模型训练和评估的**核心指标**。

- **真实情况**： 在一句话“我今天要去公___”中，下一个字**真实**是“园”。
- **模型的预测**： 模型计算出一个概率分布，比如：
  - “园” ：80% 的概率 （猜得挺准）
  - “司” ：15% 的概率
  - “共” ：5% 的概率
  - 此时，模型预测的分布和真实分布（100%是“园”）之间的差距，就是**交叉熵**。这个值会比较小。
- **如果模型预测得很差**：
  - “园” ：5% 的概率
  - “司” ：90% 的概率
  - “共” ：5% 的概率
  - 当真实答案“园”出现时，模型会感到“非常惊讶”，此时的**交叉熵**值就会很大。

**模型的目标就是通过调整参数，让自己在预测下一个字时，交叉熵尽可能的小**，也就是预测得越来越准。



### Entropy vs Cross-Entropy

| 概念                       | 通俗解释                       | 衡量对象                             | 在语言模型中的作用                                           |
| :------------------------- | :----------------------------- | :----------------------------------- | :----------------------------------------------------------- |
| 熵 (Entropy)           | 事情本身的混乱、不确定程度 | 单一的概率分布（真实世界）           | 衡量一段文本固有的不可预测性。                               |
| 交叉熵 (Cross-Entropy) | 我的预测和现实差距有多大   | 两个概率分布（我的预测 vs 真实情况） | 核心目标！ 评估模型预测得好不好。值越小，说明模型预测得越准。 |

**一句话理清关系：**
交叉熵 = 熵 + KL散度（相对熵）

你可以理解为：**预测的差距（交叉熵） = 事情本身的不确定性（熵） + 我预测的错误程度（KL散度）**。

对于一个完美的模型，它的预测和真实情况完全一样，那么交叉熵就等于熵本身。但在现实中，模型总有误差，所以交叉熵永远大于熵。我们的目标就是让交叉熵无限接近熵这个理论下限。



### 核心思想：信息的“压缩”

想象一下，你要把一本书用电报发出去，电报按“比特”（bit）收费。每个比特就是一个0或1。

- **一本内容随机的书（熵很高）**：你几乎无法预测下一个字是什么，所以你没法压缩，每个字都需要用很长的二进制码来表示。发送成本很高。
- **一本内容有规律的书（熵很低）**：比如一本只重复“abcabcabc...”的书。你可以创建一个非常简短的代码（比如就用“1”来代表整个序列），发送成本极低。

语言模型就像一个**超级压缩器**。它通过学习文本的规律，试图用最短的代码来表示文本。**BPC 和 BPB 就是衡量这个“压缩后平均每个符号用了多短的代码”的指标。**



## BPC

> Bits-per-Character (BPC) - 每字符比特数

- **它是什么？** 模型表示**一个字符（Character）** 平均需要消耗的比特（bit）数。
- **字符是什么？** 在英文中，差不多就是字母（a, b, c,...）、数字、标点符号。在中文中，通常就是指**一个汉字**。
- **怎么理解？** 如果模型的计算结果是 **1.5 BPC**，意思是：模型平均用 **1.5 个比特** 的“代码”就能表示一个汉字。
  - 这个值越低，说明模型对文本的规律把握得越好，预测下一个字越准，所以需要的“代码”就越短。
  - 它直接由我们上面讲的**交叉熵**计算而来（在数学上，交叉熵的值就是以比特为单位的平均长度）。所以，**BPC 其实就是模型在字符级别上的交叉熵值**。

**例子：**
一个训练好的中文模型在测试集上得到 1.2 BPC，意味着它非常厉害，平均每个汉字只用了 1.2 比特来编码，压缩效率很高。



## BPB

>  Bits-per-Byte (BPB) - 每字节比特数

- **它是什么？** 模型表示**一个字节（Byte）** 的平均比特数。
- **字节是什么？** 计算机存储的基本单位。1 个 Byte = 8 个 Bits。任何文件（文本、图片、视频）在计算机底层都是以字节序列的形式存储的。
- **为什么需要它？** 当模型处理的是**原始字节数据（Byte-level Data）** 而不是字符时，就用这个指标。它把文本看作一个纯粹的字节流，不考虑字符编码（如UTF-8）。

**BPC 和 BPB 的关键区别与联系：**

1. **处理层级不同**：
   - **BPC** 在**字符（Character）** 层级工作，对人类更直观。
   - **BPB** 在**字节（Byte）** 层级工作，对计算机更底层。
2. **数值范围不同**：
   - 由于 1 个字符（尤其是一个汉字）在 UTF-8 编码下通常需要 **2到4个字节** 来表示，所以 **BPC 的值通常会比 BPB 大**。
   - 举例：一个汉字“中”的UTF-8编码是3个字节（`0xE4 0xB8 0xAD`）。
     - 如果模型在这个汉字上的“损失”是 2.4 bits。
     - 那么计算 **BPC** 时，分母是 **1**（一个字符），所以贡献为 2.4。
     - 计算 **BPB** 时，分母是 **3**（三个字节），所以每个字节平均贡献 2.4 / 3 = 0.8。
3. **可比性**：
   - **不能直接比较 BPC 和 BPB 的数值**！因为它们的分母单位完全不同。一个在 1-10 范围，一个在 0-8 范围。
   - 它们只能在**相同的建模层级**（字符级或字节级）的模型之间进行比较。比如，字符级模型用 BPC 排名，字节级模型用 BPB 排名。



### BPC vs BPB

| 指标    | 全称               | 衡量什么？                             | 适用场景                              | 通俗理解                                   |
| :------ | :----------------- | :------------------------------------- | :------------------------------------ | :----------------------------------------- |
| **BPC** | Bits-per-Character | 模型压缩**一个字符**所需的平均比特数。 | **字符级（Character-level）语言模型** | 评价一个能看懂“字”的模型的压缩效率。       |
| **BPB** | Bits-per-Byte      | 模型压缩**一个字节**所需的平均比特数。 | **字节级（Byte-level）语言模型**      | 评价一个直接处理“二进制”的模型的压缩效率。 |

**最重要的共同点：**
**BPC 和 BPB 都是交叉熵的实现方式，数值都是越低越好。** 它们是从“数据压缩”角度衡量语言模型性能的黄金标准。一个更低的 BPC/BPB 值意味着模型更聪明，不确定性更小，预测更准确。



## Perplexity

> *Perplexity* is the exponential of entropy and cross entropy. 
>
> If cross entropy measures how difficult it is for a model to predict the next token, perplexity measures the amount of uncertainty it has when predictingthe next token. Higher uncertainty means there are more possible options for the next token.

如果说 **交叉熵（以及BPC/BPB）** 是衡量模型“平均有多惊讶”的尺子，那么 **Perplexity（困惑度）** 就是这把尺子的一个更直观、更有冲击力的“指数放大版”。



**核心思想：模型面临的“选择难度”**

**Perplexity 的核心含义是：模型在预测下一个 token（字/词）时，它觉得平均有多少个选项是看起来差不多、让它很“困惑”的。**

这个值越低，说明模型越自信、越准确。



**一个完美的例子：猜词游戏**

假设我们让模型玩“完形填空”，每次只预测下一个词。

- **场景一：非常简单的预测**
  - 句子：“地球是___的”
  - 模型认为：
    - “圆” ：99% 概率
    - “方” ：1% 概率
    - 其他所有词：0% 概率
  - **模型困惑吗？** 一点也不困惑！答案非常明显，几乎只有一个选择（“圆”）。所以它的**困惑度很低**。
- **场景二：非常困难的预测**
  - 句子：“今天天气真___”
  - 模型认为：
    - “好” ：20% 概率
    - “不错” ：20% 概率
    - “热” ：15% 概率
    - “冷” ：15% 概率
    - “糟糕” ：10% 概率
    - ...还有10个词平分剩下的20%概率
  - **模型困惑吗？** 非常困惑！它面前好像有十几个看似都可能的选项，它无法确定是哪一个。所以它的**困惑度很高**。



**与交叉熵的数学关系（最简单直观的解释）**

你不需要记住公式，只需要理解这个关系：

**Perplexity = 2^(交叉熵)**

- **交叉熵 (Cross-Entropy)**：衡量“平均惊讶度”，单位是比特（bits）。
- **Perplexity**：把“平均惊讶度”指数放大，变成一个更直观的“等效选项数”。

**让我们看一个例子：**

假设一个语言模型在测试集上的交叉熵是 **4 bits**。

它的困惑度就是：`Perplexity = 2^4 = 16`

**这代表什么？**
这意味着，模型在预测每一个下一个词时，其感受到的**不确定性**，相当于在一个**完全均匀分布、有16个候选词**的集合里做选择。

- 如果模型完美（交叉熵=0），困惑度就是 `2^0 = 1`。这意味着完全没有困惑，模型100%确定下一个词是什么。
- 如果模型很差（交叉熵很大，比如=10），困惑度就是 `2^10 = 1024`。这意味着模型平均觉得有1024个词都可能是答案，它简直要崩溃了。



**为什么既要交叉熵又要困惑度？**

两者本质上是同一个东西，只是表达方式不同，各有优劣：

| 指标       | 优点                                                         | 缺点                                                         | 通俗比喻                                                     |
| :--------- | :----------------------------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| **交叉熵** | **理论上的黄金标准**。数学性质好，便于计算和优化。           | 数值不够直观。你说“模型交叉熵是4.2”，别人不知道这到底算好还是坏。 | 就像测量身体的“炎症指数”，精确但抽象。                       |
| **困惑度** | **极其直观**！一听就明白。“困惑度是100”比“交叉熵是6.64”更有冲击力。 | 数学计算上不如交叉熵方便。                                   | 就像把“炎症指数”翻译成“你感冒的程度相当于同时得了3种流感”，瞬间就懂了。 |

**在学术界和工业界：**

- **训练模型时**，内部损失函数通常基于**交叉熵**进行计算和梯度下降。
- **评估和报告模型性能时**，大家更倾向于使用**困惑度**，因为它太容易理解和比较了。
  - “我们的新模型在WikiText-103数据集上将困惑度从20降到了15！”——这是一个非常有力且清晰的结论。

**总结**

- **交叉熵**：模型预测的**平均不确定性的精确度量**（单位：比特）。
- **困惑度**：交叉熵的**直观版**。它告诉你模型的不确定性相当于在多少个均等选项里做选择。

**记住一个简单的结论即可：**
**对于语言模型，困惑度越低越好。困惑度降低是模型变强的最直接、最核心的指标之一。** 一个困惑度从100降到50的模型，其性能是巨大的飞跃。



# LLM Benchmarks

> 大语言模型基准测试就像是一套为AI大模型设计的“统一高考试卷”。它的主要目的是科学、公平、全面地评估和比较不同大语言模型（LLM）在各种任务上的能力表现。

下面是一个主流的LLM Benchmarks分类及其代表性测试集合的表格，帮助你快速了解：

| 基准测试类型      | 代表Benchmarks                                  | 主要评测方向                                         |
| :---------------- | :---------------------------------------------- | :--------------------------------------------------- |
| **通用能力**      | MMLU, GPQA, BBH (BIG-Bench Hard), Chatbot Arena | 语言理解、常识、推理、知识广度等综合能力             |
| **数学能力**      | GSM8K, MATH                                     | 数学解题，尤其是多步推理能力                         |
| **代码能力**      | HumanEval, MBPP                                 | 代码生成、理解和调试能力                             |
| **中文特定**      | C-Eval, CMMLU                                   | 针对中文语言、文化和知识体系的掌握程度               |
| **安全与可靠性**  | TruthfulQA, SafetyBench, JailbreakBench         | 模型的事实真实性、抗幻觉能力、抵御恶意攻击的鲁棒性   |
| **专业领域**      | LawBench, CS-Bench, SciBench                    | 法律、计算机科学、自然科学等垂直领域的深度知识与推理 |
| **智能体(Agent)** | AgentBench, GAIA                                | 智能体的规划、工具调用、多步任务执行等能力           |



## BLEU

> **B**ilingual **E**valuation **U**nderstudy
>
> precision（精确度）裁判

**BLEU** 主要用于评估**机器翻译**的质量。

- **它的核心思想是：** “机器翻译出来的词或短语，有多少比例是出现在标准答案里的？” 它非常看重**准确性**。
- **一个简单的比喻：**
  - **标准答案（参考文本）：** “这只棕色狐狸敏捷地跳过了那只懒狗。”
  - **机器翻译（候选文本）：** “这只狐狸棕色跳过了狗。”
  - **BLEU如何评分？**
    1. 它会看单个词（1-gram）：`“这只”`、`“狐狸”`、`“棕色”`、`“跳过了”`、`“狗”` 这些词大部分都出现在标准答案里，所以会得到一个不错的分数。
    2. 它还会看词组（2-gram, 3-gram等）：比如 `“棕色狐狸”` 这个词组在标准答案里出现了，但 `“狐狸棕色”` 没有（因为词序错了）。这会扣分。
- **BLEU的缺点：**
  - **不关心流畅性和语法**：只要关键词匹配上了，哪怕句子语序混乱、不通顺，也可能得到高分。就像上面的例子，虽然词序错了，但单词基本都对。
  - **不关心含义**：它只进行表面的词匹配，不理解语义。
  - **对长度敏感**：如果候选文本太短，只包含了几个关键词，可能会得到不合理的高分。

**总结：BLEU是一个“严格的词语匹配官”，它确保翻译结果包含了正确答案中的词汇，但不保证句子通顺或词序正确。**



## ROUGE

> recall（召回率）裁判
>
> **R**ecall-**O**riented **U**nderstudy for **G**isting **E**valuation

**ROUGE** 主要用于评估**文本摘要**的质量。

- **它的核心思想是：** “标准答案（人工写的摘要）里的重要信息，有多少被机器摘要捕捉到了？” 它非常看重**覆盖度**。
- **一个简单的比喻：**
  - **原文：** 一篇长达500字关于世界杯决赛的新闻报道。
  - **标准摘要（参考文本）：** “阿根廷队在点球大战中击败法国队，梅西捧起大力神杯。”
  - **机器摘要（候选文本）：** “法国队输了。”
  - **ROUGE如何评分？**
    - 最常用的 **ROUGE-N**（如ROUGE-1, ROUGE-2）和BLEU类似，也看n-gram的重合度。
    - **但关键区别在于角度**：ROUGE关心的是**参考摘要**中的词有多少被**候选摘要**覆盖了。
    - 在上面的例子里，参考摘要中的重要词 `“阿根廷队”`、`“点球大战”`、`“梅西”`、`“大力神杯”` 在候选摘要中全部缺失了！所以ROUGE分数会非常低，因为它“召回”的信息太少了。
- **ROUGE的变种：**
  - **ROUGE-N**：计算n-gram的重合度（和BLEU很像，但出发点不同）。
  - **ROUGE-L**：不是比较独立的词组，而是看最长的公共子序列。这能更好地捕捉句子的结构和语序。
  - **ROUGE-SU**：允许跳过一些词再进行匹配，更加灵活。

**总结：ROUGE是一个“信息覆盖度检查员”，它确保摘要没有漏掉原文的核心信息。**



### BLUE vs ROUGE

| 特性         | BLEU                                       | ROUGE                                        |
| :----------- | :----------------------------------------- | :------------------------------------------- |
| **主要用途** | **机器翻译**                               | **文本摘要**                                 |
| **核心思想** | **精确度**：候选文本有多少词来自参考文本？ | **召回率**：参考文本有多少词被候选文本覆盖？ |
| **好比**     | **挑剔的语法老师**：你用的词对不对？       | **全面的阅卷老师**：你的答案要点全不全？     |
| **关注点**   | 生成的**准确性**                           | 信息的**覆盖度**                             |

**重要提示**

- **它们都是自动化的指标**，可以快速评估大量文本，成本远低于人工评审。
- **它们都不完美**：它们只进行**表面上的词法匹配**，无法真正理解**语义、连贯性、逻辑和流畅度**。一个句子可能BLEU/ROUGE分数很高但读起来很奇怪，反之亦然。
- **因此，在实际应用中，BLEU和ROUGE分数通常与人工评估结合使用**，作为衡量模型性能的一个快速、客观的参考指标，而不是唯一的黄金标准。